{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55948e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1440, 13)\n",
      "Labels shape: (1440,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory containing the audio files\n",
    "AUDIO_DIR = r\"D:\\Program\\ML\\Emotion Recognition\\audiodata\"\n",
    "\n",
    "# Initialize lists to hold features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(AUDIO_DIR):\n",
    "    if filename.endswith('.wav'):  # Check if the file is a .wav file\n",
    "        # Load the audio file\n",
    "        file_path = os.path.join(AUDIO_DIR, filename)\n",
    "        audio, sr = librosa.load(file_path, sr=None)  # Load with original sampling rate\n",
    "        \n",
    "        # Extract features (e.g., MFCCs)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "        mfccs_mean = np.mean(mfccs.T, axis=0)  # Take the mean of the MFCCs\n",
    "        \n",
    "        # Append features and label (you may need to extract the label from the filename)\n",
    "        features.append(mfccs_mean)\n",
    "        \n",
    "        # Extract label from filename (assuming the label is part of the filename)\n",
    "        label = filename.split('-')[2]  # Adjust this based on your filename format\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert features and labels to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76157310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/79 - Train Loss: 1.8170 - Train Acc: 0.3102 - Test Acc: 0.4109\n",
      "Epoch 2/79 - Train Loss: 1.4731 - Train Acc: 0.4650 - Test Acc: 0.5278\n",
      "Epoch 3/79 - Train Loss: 1.2935 - Train Acc: 0.5286 - Test Acc: 0.5868\n",
      "Epoch 4/79 - Train Loss: 1.1339 - Train Acc: 0.5923 - Test Acc: 0.6331\n",
      "Epoch 5/79 - Train Loss: 1.0317 - Train Acc: 0.6285 - Test Acc: 0.6620\n",
      "Epoch 6/79 - Train Loss: 0.9558 - Train Acc: 0.6574 - Test Acc: 0.7037\n",
      "Epoch 7/79 - Train Loss: 0.8512 - Train Acc: 0.6892 - Test Acc: 0.7384\n",
      "Epoch 8/79 - Train Loss: 0.7886 - Train Acc: 0.7245 - Test Acc: 0.7604\n",
      "Epoch 9/79 - Train Loss: 0.7228 - Train Acc: 0.7459 - Test Acc: 0.7836\n",
      "Epoch 10/79 - Train Loss: 0.6942 - Train Acc: 0.7509 - Test Acc: 0.7975\n",
      "Epoch 11/79 - Train Loss: 0.6623 - Train Acc: 0.7700 - Test Acc: 0.8194\n",
      "Epoch 12/79 - Train Loss: 0.5875 - Train Acc: 0.7925 - Test Acc: 0.8461\n",
      "Epoch 13/79 - Train Loss: 0.5738 - Train Acc: 0.8079 - Test Acc: 0.8449\n",
      "Epoch 14/79 - Train Loss: 0.5180 - Train Acc: 0.8189 - Test Acc: 0.8519\n",
      "Epoch 15/79 - Train Loss: 0.4968 - Train Acc: 0.8302 - Test Acc: 0.8692\n",
      "Epoch 16/79 - Train Loss: 0.4527 - Train Acc: 0.8478 - Test Acc: 0.8808\n",
      "Epoch 17/79 - Train Loss: 0.4241 - Train Acc: 0.8495 - Test Acc: 0.8947\n",
      "Epoch 18/79 - Train Loss: 0.4150 - Train Acc: 0.8597 - Test Acc: 0.9120\n",
      "Epoch 19/79 - Train Loss: 0.3772 - Train Acc: 0.8762 - Test Acc: 0.9039\n",
      "Epoch 20/79 - Train Loss: 0.3597 - Train Acc: 0.8802 - Test Acc: 0.9028\n",
      "Epoch 21/79 - Train Loss: 0.3706 - Train Acc: 0.8730 - Test Acc: 0.9282\n",
      "Epoch 22/79 - Train Loss: 0.3466 - Train Acc: 0.8874 - Test Acc: 0.9294\n",
      "Epoch 23/79 - Train Loss: 0.3232 - Train Acc: 0.8929 - Test Acc: 0.9375\n",
      "Epoch 24/79 - Train Loss: 0.3040 - Train Acc: 0.8999 - Test Acc: 0.9398\n",
      "Epoch 25/79 - Train Loss: 0.2800 - Train Acc: 0.9057 - Test Acc: 0.9444\n",
      "Epoch 26/79 - Train Loss: 0.2673 - Train Acc: 0.9062 - Test Acc: 0.9444\n",
      "Epoch 27/79 - Train Loss: 0.2571 - Train Acc: 0.9115 - Test Acc: 0.9583\n",
      "Epoch 28/79 - Train Loss: 0.2716 - Train Acc: 0.9106 - Test Acc: 0.9491\n",
      "Epoch 29/79 - Train Loss: 0.2476 - Train Acc: 0.9141 - Test Acc: 0.9537\n",
      "Epoch 30/79 - Train Loss: 0.2464 - Train Acc: 0.9198 - Test Acc: 0.9641\n",
      "Epoch 31/79 - Train Loss: 0.2215 - Train Acc: 0.9233 - Test Acc: 0.9641\n",
      "Epoch 32/79 - Train Loss: 0.2143 - Train Acc: 0.9248 - Test Acc: 0.9549\n",
      "Epoch 33/79 - Train Loss: 0.2950 - Train Acc: 0.9019 - Test Acc: 0.9595\n",
      "Epoch 34/79 - Train Loss: 0.2288 - Train Acc: 0.9297 - Test Acc: 0.9757\n",
      "Epoch 35/79 - Train Loss: 0.1988 - Train Acc: 0.9384 - Test Acc: 0.9734\n",
      "Epoch 36/79 - Train Loss: 0.2026 - Train Acc: 0.9337 - Test Acc: 0.9780\n",
      "Epoch 37/79 - Train Loss: 0.1859 - Train Acc: 0.9407 - Test Acc: 0.9757\n",
      "Epoch 38/79 - Train Loss: 0.1914 - Train Acc: 0.9389 - Test Acc: 0.9780\n",
      "Epoch 39/79 - Train Loss: 0.1810 - Train Acc: 0.9384 - Test Acc: 0.9734\n",
      "Epoch 40/79 - Train Loss: 0.1568 - Train Acc: 0.9491 - Test Acc: 0.9815\n",
      "Epoch 41/79 - Train Loss: 0.1562 - Train Acc: 0.9488 - Test Acc: 0.9838\n",
      "Epoch 42/79 - Train Loss: 0.1556 - Train Acc: 0.9488 - Test Acc: 0.9896\n",
      "Epoch 43/79 - Train Loss: 0.1406 - Train Acc: 0.9589 - Test Acc: 0.9792\n",
      "Epoch 44/79 - Train Loss: 0.1616 - Train Acc: 0.9482 - Test Acc: 0.9838\n",
      "Epoch 45/79 - Train Loss: 0.1547 - Train Acc: 0.9494 - Test Acc: 0.9780\n",
      "Epoch 46/79 - Train Loss: 0.1461 - Train Acc: 0.9537 - Test Acc: 0.9803\n",
      "Epoch 47/79 - Train Loss: 0.1524 - Train Acc: 0.9517 - Test Acc: 0.9711\n",
      "Epoch 48/79 - Train Loss: 0.1689 - Train Acc: 0.9450 - Test Acc: 0.9861\n",
      "Epoch 49/79 - Train Loss: 0.1330 - Train Acc: 0.9572 - Test Acc: 0.9826\n",
      "Epoch 50/79 - Train Loss: 0.1602 - Train Acc: 0.9523 - Test Acc: 0.9850\n",
      "Epoch 51/79 - Train Loss: 0.1553 - Train Acc: 0.9511 - Test Acc: 0.9861\n",
      "Epoch 52/79 - Train Loss: 0.1442 - Train Acc: 0.9552 - Test Acc: 0.9884\n",
      "Epoch 53/79 - Train Loss: 0.1398 - Train Acc: 0.9572 - Test Acc: 0.9884\n",
      "Epoch 54/79 - Train Loss: 0.1603 - Train Acc: 0.9525 - Test Acc: 0.9792\n",
      "Epoch 55/79 - Train Loss: 0.1396 - Train Acc: 0.9523 - Test Acc: 0.9780\n",
      "Epoch 56/79 - Train Loss: 0.1282 - Train Acc: 0.9589 - Test Acc: 0.9896\n",
      "Epoch 57/79 - Train Loss: 0.1191 - Train Acc: 0.9598 - Test Acc: 0.9850\n",
      "Epoch 58/79 - Train Loss: 0.1035 - Train Acc: 0.9670 - Test Acc: 0.9861\n",
      "Epoch 59/79 - Train Loss: 0.0922 - Train Acc: 0.9690 - Test Acc: 0.9896\n",
      "Epoch 60/79 - Train Loss: 0.1110 - Train Acc: 0.9679 - Test Acc: 0.9907\n",
      "Epoch 61/79 - Train Loss: 0.1143 - Train Acc: 0.9641 - Test Acc: 0.9826\n",
      "Epoch 62/79 - Train Loss: 0.0941 - Train Acc: 0.9685 - Test Acc: 0.9873\n",
      "Epoch 63/79 - Train Loss: 0.1145 - Train Acc: 0.9661 - Test Acc: 0.9803\n",
      "Epoch 64/79 - Train Loss: 0.1109 - Train Acc: 0.9624 - Test Acc: 0.9884\n",
      "Epoch 65/79 - Train Loss: 0.1163 - Train Acc: 0.9638 - Test Acc: 0.9861\n",
      "Epoch 66/79 - Train Loss: 0.1022 - Train Acc: 0.9638 - Test Acc: 0.9850\n",
      "Epoch 67/79 - Train Loss: 0.0985 - Train Acc: 0.9659 - Test Acc: 0.9896\n",
      "Epoch 68/79 - Train Loss: 0.1030 - Train Acc: 0.9690 - Test Acc: 0.9965\n",
      "Epoch 69/79 - Train Loss: 0.1050 - Train Acc: 0.9685 - Test Acc: 0.9884\n",
      "Epoch 70/79 - Train Loss: 0.1065 - Train Acc: 0.9664 - Test Acc: 0.9884\n",
      "Epoch 71/79 - Train Loss: 0.1277 - Train Acc: 0.9641 - Test Acc: 0.9942\n",
      "Epoch 72/79 - Train Loss: 0.1046 - Train Acc: 0.9633 - Test Acc: 0.9896\n",
      "Epoch 73/79 - Train Loss: 0.0900 - Train Acc: 0.9731 - Test Acc: 0.9931\n",
      "Epoch 74/79 - Train Loss: 0.1040 - Train Acc: 0.9635 - Test Acc: 0.9884\n",
      "Epoch 75/79 - Train Loss: 0.1142 - Train Acc: 0.9609 - Test Acc: 0.9896\n",
      "Epoch 76/79 - Train Loss: 0.1061 - Train Acc: 0.9679 - Test Acc: 0.9873\n",
      "Epoch 77/79 - Train Loss: 0.0870 - Train Acc: 0.9722 - Test Acc: 0.9884\n",
      "Epoch 78/79 - Train Loss: 0.1310 - Train Acc: 0.9685 - Test Acc: 0.9896\n",
      "Epoch 79/79 - Train Loss: 0.1037 - Train Acc: 0.9653 - Test Acc: 0.9873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 79\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# === Load features from CSV ===\n",
    "df = pd.read_csv(r\"D:\\Program\\ML\\Emotion Recognition\\features.csv\")\n",
    "\n",
    "# === Encode emotion labels (string â†’ int) ===\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# === Normalize features ===\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df.drop('label', axis=1))  # (samples, 193 features)\n",
    "y = df['label'].values\n",
    "\n",
    "# === Train-test split (stratified to balance classes) ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === Convert to PyTorch tensors ===\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# === Wrap tensors into TensorDatasets ===\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# === Create DataLoaders ===\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# === Define FCNN Model ===\n",
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "input_size = X.shape[1]\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "model = EmotionClassifier(input_size, num_classes).to(device)\n",
    "\n",
    "# === Loss and Optimizer ===\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# === Training Loop ===\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    correct, total, running_loss = 0, 0, 0.0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss = running_loss / total\n",
    "\n",
    "    # === Evaluation on test set ===\n",
    "    model.eval()\n",
    "    test_correct, test_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "    test_acc = test_correct / test_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - Test Acc: {test_acc:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
